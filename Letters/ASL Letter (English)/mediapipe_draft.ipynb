{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340cff33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .DS_Store files removed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = 'M:\\Term 9\\Grad\\Gradution Current Project\\Sign-Language-Recognition-System-main\\Sign-Language-Recognition-System-main\\Sign_to_Sentence Project\\Asl_Sign_Data\\asl_alphabet_train\\asl_alphabet_train'\n",
    "\n",
    "# Traverse all subdirectories and remove .DS_Store files\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            file_path = os.path.join(root, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_path}\")\n",
    "\n",
    "print(\"All .DS_Store files removed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f98537",
   "metadata": {},
   "source": [
    "Imports for the the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3bfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d37f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "GPUs detected: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPUs detected:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12772b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "True\n",
      "11.3\n",
      "NVIDIA GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ffad343",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'M:\\\\Term 9\\\\Grad\\\\Gradution Current Project\\\\Sign-Language-Recognition-System-main\\\\Sign-Language-Recognition-System-main\\\\Sign_to_Sentence Project\\\\Asl_Sign_Data\\x07sl_alphabet_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTerm 9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGrad\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGradution Current Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSign-Language-Recognition-System-main\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSign-Language-Recognition-System-main\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSign_to_Sentence Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAsl_Sign_Data\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124msl_alphabet_train\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Visualize some images\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'M:\\\\Term 9\\\\Grad\\\\Gradution Current Project\\\\Sign-Language-Recognition-System-main\\\\Sign-Language-Recognition-System-main\\\\Sign_to_Sentence Project\\\\Asl_Sign_Data\\x07sl_alphabet_train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_dir = 'M:\\Term 9\\Grad\\Gradution Current Project\\Sign-Language-Recognition-System-main\\Sign-Language-Recognition-System-main\\Sign_to_Sentence Project\\Asl_Sign_Data\\asl_alphabet_train'\n",
    "\n",
    "classes = os.listdir(dataset_dir)\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Visualize some images\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "for i, label in enumerate(classes[:5]):  # Show first 5 classes\n",
    "    class_dir = os.path.join(dataset_dir, label)\n",
    "    img_files = os.listdir(class_dir)[:3]  # Show 3 images per class\n",
    "\n",
    "    for j, img_name in enumerate(img_files):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        \n",
    "        axes[j, i].imshow(img)\n",
    "        axes[j, i].axis(\"off\")\n",
    "        axes[j, i].set_title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debca510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
