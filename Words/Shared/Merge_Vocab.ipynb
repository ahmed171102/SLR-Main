{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c616fb1",
   "metadata": {},
   "source": [
    "\n",
    "# Vocabulary Merge â€” English ASL + Arabic ArSL\n",
    "\n",
    "This notebook runs **after both** training notebooks have completed.  \n",
    "It merges the two independently-trained model class maps with the shared vocabulary so the backend knows exactly which model index corresponds to each word in both languages.\n",
    "\n",
    "### What it produces:\n",
    "\n",
    "`merged_word_vocabulary.csv` â€” one row per shared word with columns:\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `word_id` | Shared identifier (same across both models) |\n",
    "| `english` | English gloss (ASL) |\n",
    "| `arabic` | Arabic gloss (ArSL) |\n",
    "| `category` | Semantic category |\n",
    "| `wlasl_class` | WLASL class ID |\n",
    "| `karsl_class` | KArSL class ID |\n",
    "| `asl_model_index` | Index emitted by the English model's output layer |\n",
    "| `arsl_model_index` | Index emitted by the Arabic model's output layer |\n",
    "\n",
    "### When to re-run:\n",
    "\n",
    "Re-run this notebook any time you retrain either model (class indices can shift if classes are added/removed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc06e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 1: CONFIGURATION â€” single place to change\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# âš ï¸ Update if your drive letter differs\n",
    "PROJECT_ROOT = Path(r'M:/Term 10/Grad')\n",
    "\n",
    "WORDS_ROOT = PROJECT_ROOT / 'SLR Main/Words'\n",
    "SHARED_DIR = WORDS_ROOT / 'Shared'\n",
    "\n",
    "# Inputs\n",
    "SHARED_CSV   = SHARED_DIR / 'shared_word_vocabulary.csv'\n",
    "ASL_CSV      = WORDS_ROOT / 'ASL Word (English)/asl_word_classes.csv'\n",
    "ARSL_CSV     = WORDS_ROOT / 'ArSL Word (Arabic)/arsl_word_classes.csv'\n",
    "\n",
    "# Output\n",
    "OUTPUT_CSV   = SHARED_DIR / 'merged_word_vocabulary.csv'\n",
    "\n",
    "# â”€â”€ Verify inputs exist â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('=' * 60)\n",
    "print('ðŸ“‚ INPUT FILES')\n",
    "print('=' * 60)\n",
    "for label, path in [('Shared vocab', SHARED_CSV),\n",
    "                    ('ASL classes',  ASL_CSV),\n",
    "                    ('ArSL classes', ARSL_CSV)]:\n",
    "    status = 'âœ…' if path.exists() else 'âš ï¸  NOT FOUND (train the model first)'\n",
    "    print(f'{status}  {label}: {path.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eac6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 2: LOAD SHARED VOCABULARY\n",
    "# ============================================================\n",
    "shared = pd.read_csv(SHARED_CSV)\n",
    "shared['word_id'] = shared['word_id'].astype(int)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'ðŸ“– Shared vocabulary: {len(shared)} words')\n",
    "print(f'   Columns: {list(shared.columns)}')\n",
    "print(f'   Categories: {sorted(shared[\"category\"].unique())}')\n",
    "print()\n",
    "print(shared.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 3: LOAD ENGLISH (ASL) CLASS MAP\n",
    "# ============================================================\n",
    "# asl_word_classes.csv has columns: model_class_index, word_id\n",
    "# model_class_index = the integer the English model outputs (0â€¦N-1)\n",
    "\n",
    "if ASL_CSV.exists():\n",
    "    asl_df = pd.read_csv(ASL_CSV)\n",
    "    asl_df['word_id'] = asl_df['word_id'].astype(int)\n",
    "    asl_df = asl_df.rename(columns={'model_class_index': 'asl_model_index'})\n",
    "    print(f'âœ… ASL class map loaded: {len(asl_df)} classes')\n",
    "    print(f'   word_id range     : {asl_df[\"word_id\"].min()} â€“ {asl_df[\"word_id\"].max()}')\n",
    "    print(f'   model_index range : {asl_df[\"asl_model_index\"].min()} â€“ {asl_df[\"asl_model_index\"].max()}')\n",
    "    print(asl_df.head(5).to_string(index=False))\n",
    "else:\n",
    "    asl_df = pd.DataFrame(columns=['word_id', 'asl_model_index'])\n",
    "    print('âš ï¸  asl_word_classes.csv not found â€” ASL model index will be NaN in output.')\n",
    "    print('    Train the English notebook first, then re-run this notebook.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 4: LOAD ARABIC (ArSL) CLASS MAP\n",
    "# ============================================================\n",
    "# arsl_word_classes.csv has columns: model_class_index, word_id\n",
    "\n",
    "if ARSL_CSV.exists():\n",
    "    arsl_df = pd.read_csv(ARSL_CSV)\n",
    "    arsl_df['word_id'] = arsl_df['word_id'].astype(int)\n",
    "    arsl_df = arsl_df.rename(columns={'model_class_index': 'arsl_model_index'})\n",
    "    print(f'âœ… ArSL class map loaded: {len(arsl_df)} classes')\n",
    "    print(f'   word_id range     : {arsl_df[\"word_id\"].min()} â€“ {arsl_df[\"word_id\"].max()}')\n",
    "    print(f'   model_index range : {arsl_df[\"arsl_model_index\"].min()} â€“ {arsl_df[\"arsl_model_index\"].max()}')\n",
    "    print(arsl_df.head(5).to_string(index=False))\n",
    "else:\n",
    "    arsl_df = pd.DataFrame(columns=['word_id', 'arsl_model_index'])\n",
    "    print('âš ï¸  arsl_word_classes.csv not found â€” ArSL model index will be NaN in output.')\n",
    "    print('    Train the Arabic notebook first, then re-run this notebook.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 5: MERGE INTO UNIFIED VOCABULARY\n",
    "# ============================================================\n",
    "# Merge ASL model indices into shared vocab (left join â€” keeps all shared words)\n",
    "merged = shared.copy()\n",
    "\n",
    "if len(asl_df) > 0:\n",
    "    merged = merged.merge(asl_df[['word_id', 'asl_model_index']], on='word_id', how='left')\n",
    "else:\n",
    "    merged['asl_model_index'] = pd.NA\n",
    "\n",
    "if len(arsl_df) > 0:\n",
    "    merged = merged.merge(arsl_df[['word_id', 'arsl_model_index']], on='word_id', how='left')\n",
    "else:\n",
    "    merged['arsl_model_index'] = pd.NA\n",
    "\n",
    "# Use nullable integer type so NaN displays cleanly\n",
    "merged['asl_model_index']  = merged['asl_model_index'].astype('Int64')\n",
    "merged['arsl_model_index'] = merged['arsl_model_index'].astype('Int64')\n",
    "\n",
    "# Reorder columns for readability\n",
    "col_order = ['word_id', 'english', 'arabic', 'category',\n",
    "             'wlasl_class', 'karsl_class',\n",
    "             'asl_model_index', 'arsl_model_index']\n",
    "for c in col_order:\n",
    "    if c not in merged.columns:\n",
    "        merged[c] = pd.NA\n",
    "merged = merged[col_order]\n",
    "\n",
    "print('=' * 60)\n",
    "print('ðŸ”€ MERGED VOCABULARY')\n",
    "print('=' * 60)\n",
    "print(f'   Total rows             : {len(merged)}')\n",
    "print(f'   Words with ASL index   : {merged[\"asl_model_index\"].notna().sum()}')\n",
    "print(f'   Words with ArSL index  : {merged[\"arsl_model_index\"].notna().sum()}')\n",
    "print(f'   Words in BOTH models   : {(merged[\"asl_model_index\"].notna() & merged[\"arsl_model_index\"].notna()).sum()}')\n",
    "print()\n",
    "print(merged.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 6: SEPARATE BACK INTO ENGLISH-ONLY / ARABIC-ONLY VIEWS\n",
    "# ============================================================\n",
    "# These are read-only views â€” the source of truth is merged_word_vocabulary.csv\n",
    "\n",
    "# English words that have a trained ASL model class\n",
    "english_vocab = merged[merged['asl_model_index'].notna()].copy()\n",
    "english_vocab = english_vocab[['word_id', 'english', 'category', 'wlasl_class', 'asl_model_index']]\n",
    "english_vocab = english_vocab.sort_values('asl_model_index').reset_index(drop=True)\n",
    "\n",
    "# Arabic words that have a trained ArSL model class\n",
    "arabic_vocab = merged[merged['arsl_model_index'].notna()].copy()\n",
    "arabic_vocab = arabic_vocab[['word_id', 'arabic', 'category', 'karsl_class', 'arsl_model_index']]\n",
    "arabic_vocab = arabic_vocab.sort_values('arsl_model_index').reset_index(drop=True)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'ðŸ‡ºðŸ‡¸ English (ASL) vocab : {len(english_vocab)} words')\n",
    "print('=' * 60)\n",
    "print(english_vocab.head(8).to_string(index=False))\n",
    "print()\n",
    "print('=' * 60)\n",
    "print(f'ðŸ‡¸ðŸ‡¦ Arabic (ArSL) vocab : {len(arabic_vocab)} words')\n",
    "print('=' * 60)\n",
    "print(arabic_vocab.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833baa74",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "\n",
    "| File | Description |\n",
    "|---|---|\n",
    "| `merged_word_vocabulary.csv` | Full bilingual vocabulary â€” **use this in the backend** |\n",
    "| `english_word_vocabulary.csv` | English-only filtered view (rows with ASL model index) |\n",
    "| `arabic_word_vocabulary.csv` | Arabic-only filtered view (rows with ArSL model index) |\n",
    "\n",
    "### Re-train workflow:\n",
    "\n",
    "```\n",
    "1. Run ASL Word (English)/ASL_Word_Training.ipynb   â†’ produces asl_word_classes.csv\n",
    "2. Run ArSL Word (Arabic)/ArSL_Word_Training.ipynb  â†’ produces arsl_word_classes.csv\n",
    "3. Run THIS notebook                                â†’ produces merged_word_vocabulary.csv\n",
    "```\n",
    "\n",
    "### If a model index column is NaN:\n",
    "\n",
    "The model hasn't been trained yet for those words. Train the missing notebook then re-run this one.\n",
    "\n",
    "### Adding new words:\n",
    "\n",
    "1. Add new rows to `shared_word_vocabulary.csv` with unique `word_id`\n",
    "2. Re-train both models (they will auto-detect the new vocab)\n",
    "3. Re-run this notebook to regenerate the merged file\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
