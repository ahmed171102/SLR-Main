{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ba72f0",
   "metadata": {},
   "source": [
    "# ASL Word Recognition V2 ‚Äî CNN-BiLSTM + Transformer Ensemble (Max Accuracy)\n",
    "\n",
    "**Ground-up redesign** for maximum word-level ASL accuracy using WLASL + MediaPipe two-hand landmarks.\n",
    "\n",
    "### Architecture Highlights:\n",
    "\n",
    "- **CNN-BiLSTM + TransformerBlock + TemporalAttention** ‚Äî deep hybrid architecture\n",
    "- **Sequence length 60** (2√ó the baseline) ‚Äî more temporal context\n",
    "- **Wrist-relative + scale normalization** ‚Äî translation & scale invariant features\n",
    "- **CategoricalFocalCrossentropy (Œ≥=2)** ‚Äî handles class imbalance far better than CE\n",
    "- **Cosine Decay + Linear Warmup** LR schedule ‚Äî stable convergence\n",
    "- **Ensemble of 3 models**: CNN-BiLSTM, Pure Transformer, TCN\n",
    "- **Aggressive augmentation**: noise, shift, frame dropout, scale, hand swap, rotation, speed perturbation\n",
    "- **Mixed float16 precision** on dense layers, float32 on LSTM\n",
    "\n",
    "### Output Artifacts:\n",
    "\n",
    "- `asl_word_lstm_v2_best.h5` ‚Äî best single CNN-BiLSTM model\n",
    "- `asl_word_ensemble_final.h5` ‚Äî final ensemble model\n",
    "- `scaler.pkl`, `encoder.pkl` ‚Äî preprocessing objects\n",
    "- `asl_word_classes_v2.csv` ‚Äî class mapping\n",
    "\n",
    "### Setup:\n",
    "\n",
    "1. Upload metadata CSVs/JSONs and WLASL videos as Kaggle datasets (or set local paths in Cell 3)\n",
    "2. Enable GPU accelerator\n",
    "3. Run all cells in order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 1: INSTALL DEPENDENCIES & IMPORTS\n",
    "# ===============================================================\n",
    "import subprocess, sys\n",
    "\n",
    "def pip_install(pkg):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
    "\n",
    "pip_install('mediapipe==0.10.13')\n",
    "pip_install('joblib')\n",
    "\n",
    "import json, os, time, math, pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization, LayerNormalization,\n",
    "    LSTM, Bidirectional, Conv1D, DepthwiseConv2D,\n",
    "    GlobalAveragePooling1D, SpatialDropout1D,\n",
    "    MultiHeadAttention, Add, Reshape, Lambda\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,\n",
    "    TerminateOnNaN, CSVLogger\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('=' * 65)\n",
    "print('‚úÖ All libraries imported successfully')\n",
    "print(f'   TensorFlow : {tf.__version__}')\n",
    "print(f'   MediaPipe  : {mp.__version__}')\n",
    "print(f'   NumPy      : {np.__version__}')\n",
    "print('=' * 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 2: GPU CONFIGURATION & MIXED PRECISION SETUP\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üîç GPU DETECTION & MIXED PRECISION CONFIGURATION')\n",
    "print('=' * 65)\n",
    "\n",
    "print(f'\\nTensorFlow  : {tf.__version__}')\n",
    "print(f'Built w/CUDA: {tf.test.is_built_with_cuda()}')\n",
    "print(f'All devices : {tf.config.list_physical_devices()}')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'\\nüéÆ GPU Devices: {len(gpus)}')\n",
    "\n",
    "USE_GPU = False\n",
    "DEVICE  = '/CPU:0'\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        USE_GPU = True\n",
    "        DEVICE  = '/GPU:0'\n",
    "        print(f'‚úÖ GPU enabled: {gpus[0].name}')\n",
    "        try:\n",
    "            d = tf.config.experimental.get_device_details(gpus[0])\n",
    "            print(f'   Device        : {d.get(\"device_name\", \"N/A\")}')\n",
    "            print(f'   Compute Cap.  : {d.get(\"compute_capability\", \"N/A\")}')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # GPU benchmark\n",
    "        print('\\nüß™ GPU Benchmark (matmul 4096√ó4096)...')\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.random.normal([4096, 4096])\n",
    "            t0 = time.time()\n",
    "            c = tf.matmul(a, tf.transpose(a))\n",
    "            _ = c.numpy()\n",
    "            print(f'   ‚úÖ {time.time()-t0:.3f}s  |  result shape: {c.shape}')\n",
    "    except RuntimeError as e:\n",
    "        print(f'‚ö†Ô∏è  GPU config error: {e}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  No GPU ‚Äî CPU only (training will be slow)')\n",
    "\n",
    "# Mixed precision: float16 for dense layers, float32 kept for LSTM via dtype override\n",
    "# We set global policy to float32 for stability; LSTM+Conv layers stay float32 naturally.\n",
    "# For dense/attention layers on GPU, we can cast manually.\n",
    "ENABLE_MIXED_PRECISION = USE_GPU  # only on GPU\n",
    "if ENABLE_MIXED_PRECISION:\n",
    "    try:\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "        print(f'\\n‚ö° Mixed precision: mixed_float16 enabled')\n",
    "    except Exception as e:\n",
    "        ENABLE_MIXED_PRECISION = False\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "        print(f'\\n‚ö†Ô∏è  Mixed precision failed ({e}), using float32')\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(f'\\nüìê Precision: float32')\n",
    "\n",
    "print(f'\\n‚úÖ Device ready: {DEVICE}')\n",
    "print('=' * 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 3: PATH CONFIGURATION & HYPERPARAMETERS (MAX SETTINGS)\n",
    "# ===============================================================\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print('üîç Kaggle environment ‚Äî auto-searching for files...')\n",
    "    KAGGLE_INPUT = Path('/kaggle/input')\n",
    "    OUTPUT_DIR   = Path('/kaggle/working')\n",
    "    try:\n",
    "        SHARED_CSV  = next(KAGGLE_INPUT.rglob('shared_word_vocabulary.csv'))\n",
    "        WLASL_JSON  = next(KAGGLE_INPUT.rglob('WLASL_v0.3.json'))\n",
    "        NSLT_SPLIT  = next(KAGGLE_INPUT.rglob('nslt_2000.json'))\n",
    "        MISSING_TXT = next(KAGGLE_INPUT.rglob('missing.txt'))\n",
    "        video_dirs  = [p for p in KAGGLE_INPUT.rglob('videos') if p.is_dir()]\n",
    "        VIDEO_DIR   = video_dirs[0] if video_dirs else None\n",
    "    except StopIteration:\n",
    "        print('‚ùå Missing files ‚Äî check dataset attachments')\n",
    "        SHARED_CSV = WLASL_JSON = NSLT_SPLIT = MISSING_TXT = VIDEO_DIR = None\n",
    "else:\n",
    "    # ‚îÄ‚îÄ LOCAL PATHS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    PROJECT_ROOT = Path(r'D:\\My_Graduation_Project')\n",
    "    SHARED_CSV   = PROJECT_ROOT / 'shared_word_vocabulary.csv'\n",
    "    WLASL_JSON   = PROJECT_ROOT / 'WLASL_v0.3.json'\n",
    "    NSLT_SPLIT   = PROJECT_ROOT / 'nslt_2000.json'\n",
    "    MISSING_TXT  = PROJECT_ROOT / 'missing.txt'\n",
    "    VIDEO_DIR    = PROJECT_ROOT / 'videos'\n",
    "    OUTPUT_DIR   = PROJECT_ROOT / 'ASL_Word_Output_V2'\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ HYPERPARAMETERS (MAXIMUM VIABLE SETTINGS) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SEQUENCE_LENGTH     = 60          # 2√ó baseline ‚Äî richer temporal context\n",
    "NUM_HANDS           = 2\n",
    "LANDMARKS_PER_HAND  = 63          # 21 landmarks √ó 3 (x, y, z)\n",
    "NUM_FEATURES        = NUM_HANDS * LANDMARKS_PER_HAND   # 126\n",
    "\n",
    "# Model capacity\n",
    "LSTM_UNITS_1        = 768\n",
    "LSTM_UNITS_2        = 512\n",
    "LSTM_UNITS_3        = 256\n",
    "DENSE_UNITS         = 1024\n",
    "CNN_FILTERS_1       = 256\n",
    "CNN_FILTERS_2       = 256\n",
    "CNN_FILTERS_3       = 512\n",
    "NUM_TRANSFORMER_HEADS = 8\n",
    "TRANSFORMER_FF_DIM  = 512\n",
    "NUM_TRANSFORMER_BLOCKS = 3        # stacked transformer blocks\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE          = 128 if USE_GPU else 32\n",
    "EPOCHS              = 300\n",
    "LEARNING_RATE       = 3e-4\n",
    "WARMUP_EPOCHS       = 10\n",
    "DROPOUT_RATE        = 0.4\n",
    "SPATIAL_DROPOUT     = 0.2\n",
    "LABEL_SMOOTH        = 0.05\n",
    "GRAD_CLIP_NORM      = 0.5\n",
    "L2_REG              = 5e-5\n",
    "WEIGHT_DECAY        = 1e-4\n",
    "FOCAL_GAMMA         = 2.0         # Focal loss gamma\n",
    "TEST_SIZE           = 0.3         # 70/15/15 split\n",
    "\n",
    "# ‚îÄ‚îÄ VERIFY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('\\n‚îÄ‚îÄ PATH VERIFICATION ‚îÄ‚îÄ')\n",
    "for name, path in [('Shared CSV', SHARED_CSV), ('WLASL JSON', WLASL_JSON),\n",
    "                   ('NSLT Split', NSLT_SPLIT), ('Missing TXT', MISSING_TXT)]:\n",
    "    ok = path and Path(path).exists()\n",
    "    print(f'  {\"‚úÖ\" if ok else \"‚ùå\"} {name}: {path}')\n",
    "ok_v = VIDEO_DIR and Path(VIDEO_DIR).exists()\n",
    "print(f'  {\"‚úÖ\" if ok_v else \"‚ùå\"} Video dir : {VIDEO_DIR}')\n",
    "print(f'  üìÅ Output dir : {OUTPUT_DIR}')\n",
    "\n",
    "print('\\n‚îÄ‚îÄ HYPERPARAMETERS ‚îÄ‚îÄ')\n",
    "print(f'  Sequence length   : {SEQUENCE_LENGTH}')\n",
    "print(f'  Features/frame    : {NUM_FEATURES}')\n",
    "print(f'  LSTM units        : {LSTM_UNITS_1}/{LSTM_UNITS_2}/{LSTM_UNITS_3}')\n",
    "print(f'  Dense units       : {DENSE_UNITS}')\n",
    "print(f'  Transformer heads : {NUM_TRANSFORMER_HEADS}  (blocks: {NUM_TRANSFORMER_BLOCKS})')\n",
    "print(f'  Batch size        : {BATCH_SIZE}  |  Epochs: {EPOCHS}')\n",
    "print(f'  LR                : {LEARNING_RATE}  (warmup {WARMUP_EPOCHS} ep)')\n",
    "print(f'  Dropout           : {DROPOUT_RATE}  |  Focal Œ≥: {FOCAL_GAMMA}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 4: LOAD VOCABULARY & WLASL METADATA\n",
    "# ===============================================================\n",
    "vocab_df = pd.read_csv(SHARED_CSV)\n",
    "vocab_df = vocab_df.dropna(subset=['wlasl_class'])\n",
    "vocab_df['wlasl_class'] = vocab_df['wlasl_class'].astype(int)\n",
    "\n",
    "matched_wlasl_classes = set(vocab_df['wlasl_class'].tolist())\n",
    "wlasl_to_wordid = dict(zip(vocab_df['wlasl_class'], vocab_df['word_id']))\n",
    "id_to_english   = dict(zip(vocab_df['word_id'].astype(int), vocab_df['english']))\n",
    "\n",
    "with open(NSLT_SPLIT, 'r', encoding='utf-8') as f:\n",
    "    nslt = json.load(f)\n",
    "with open(MISSING_TXT, 'r', encoding='utf-8') as f:\n",
    "    missing_ids = set(x.strip() for x in f if x.strip())\n",
    "with open(WLASL_JSON, 'r', encoding='utf-8') as f:\n",
    "    wlasl_data = json.load(f)\n",
    "\n",
    "download_list = []\n",
    "for entry in wlasl_data:\n",
    "    gloss = entry.get('gloss', '')\n",
    "    for inst in entry.get('instances', []):\n",
    "        vid = inst.get('video_id')\n",
    "        if not vid or vid not in nslt or vid in missing_ids:\n",
    "            continue\n",
    "        class_id = int(nslt[vid]['action'][0])\n",
    "        if class_id not in matched_wlasl_classes:\n",
    "            continue\n",
    "        download_list.append({\n",
    "            'video_id': vid,\n",
    "            'url':       inst.get('url'),\n",
    "            'class_id':  class_id,\n",
    "            'word_id':   int(wlasl_to_wordid[class_id]),\n",
    "            'gloss':     gloss,\n",
    "            'subset':    nslt[vid]['subset']\n",
    "        })\n",
    "\n",
    "dl_df = pd.DataFrame(download_list)\n",
    "print(f'üì• Total video candidates : {len(dl_df)}')\n",
    "print(f'üè∑Ô∏è  Unique WLASL classes   : {dl_df[\"class_id\"].nunique()}')\n",
    "print(f'üìñ Vocabulary size         : {len(vocab_df)} words')\n",
    "\n",
    "if 'category' in vocab_df.columns:\n",
    "    cat_counts = vocab_df['category'].value_counts()\n",
    "    print(f'\\nüìã Category breakdown:\\n{cat_counts.to_string()}')\n",
    "\n",
    "subset_counts = dl_df['subset'].value_counts()\n",
    "print(f'\\nüìÇ Subset breakdown:\\n{subset_counts.to_string()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 5: ENHANCED TWO-HAND LANDMARK EXTRACTION WITH NORMALIZATION\n",
    "# ===============================================================\n",
    "# Features: wrist-relative + scale normalization for translation/scale invariance\n",
    "# Strict quality filter: skip if <30% frames have hands detected\n",
    "# Sequence length = 60 frames (2√ó baseline)\n",
    "# Saves to asl_word_sequences_2hand_v2.npz  ‚Äî skip if already exists\n",
    "\n",
    "NPZ_PATH = OUTPUT_DIR / 'asl_word_sequences_2hand_v2.npz'\n",
    "\n",
    "def normalize_hand(landmarks_21x3: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Wrist-relative + scale normalization.\n",
    "    landmarks_21x3: shape (21, 3)\n",
    "    Returns: (21*3,) = (63,) normalized vector\n",
    "    \"\"\"\n",
    "    wrist = landmarks_21x3[0].copy()   # landmark 0 = wrist\n",
    "    rel = landmarks_21x3 - wrist       # translate so wrist is at origin\n",
    "\n",
    "    # scale: distance from wrist to middle-finger MCP (landmark 9)\n",
    "    dist = np.linalg.norm(rel[9])\n",
    "    if dist > 1e-6:\n",
    "        rel = rel / dist               # scale invariant\n",
    "    return rel.flatten()\n",
    "\n",
    "if NPZ_PATH.exists():\n",
    "    print(f'‚è© Dataset already exists ‚Äî loading from cache')\n",
    "    data = np.load(NPZ_PATH)\n",
    "    X, y = data['X'], data['y']\n",
    "    print(f'   X: {X.shape} | y: {y.shape} | classes: {len(np.unique(y))}')\n",
    "else:\n",
    "    mp_hands = mp.solutions.hands\n",
    "    detector = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "\n",
    "    def extract_frame(frame):\n",
    "        rgb    = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = detector.process(rgb)\n",
    "        left_v  = np.zeros(LANDMARKS_PER_HAND, dtype=np.float32)\n",
    "        right_v = np.zeros(LANDMARKS_PER_HAND, dtype=np.float32)\n",
    "        if result.multi_hand_landmarks and result.multi_handedness:\n",
    "            for lm, hd in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                pts = np.array([[p.x, p.y, p.z] for p in lm.landmark])  # (21, 3)\n",
    "                vec = normalize_hand(pts)\n",
    "                if hd.classification[0].label == 'Left':\n",
    "                    left_v = vec\n",
    "                else:\n",
    "                    right_v = vec\n",
    "        return np.concatenate([left_v, right_v]), (left_v.any() or right_v.any())\n",
    "\n",
    "    def extract_video(path):\n",
    "        cap  = cv2.VideoCapture(str(path))\n",
    "        if not cap.isOpened():\n",
    "            return None, 0\n",
    "        frames, detected = [], 0\n",
    "        while True:\n",
    "            ret, f = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            vec, saw = extract_frame(f)\n",
    "            frames.append(vec)\n",
    "            if saw:\n",
    "                detected += 1\n",
    "        cap.release()\n",
    "        if not frames:\n",
    "            return None, 0\n",
    "        arr = np.array(frames, dtype=np.float32)\n",
    "        detect_rate = detected / len(arr)\n",
    "\n",
    "        # Resample to SEQUENCE_LENGTH via linear interpolation\n",
    "        if len(arr) >= SEQUENCE_LENGTH:\n",
    "            idx = np.linspace(0, len(arr) - 1, SEQUENCE_LENGTH, dtype=int)\n",
    "            arr = arr[idx]\n",
    "        else:\n",
    "            pad = np.zeros((SEQUENCE_LENGTH - len(arr), NUM_FEATURES), dtype=np.float32)\n",
    "            arr = np.concatenate([arr, pad], axis=0)\n",
    "        return arr, detect_rate\n",
    "\n",
    "    meta_by_id  = {d['video_id']: d for d in download_list}\n",
    "    video_files = sorted(Path(VIDEO_DIR).glob('*.mp4'))\n",
    "    print(f'üìÅ Found {len(video_files)} video files')\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    skipped_missing, skipped_quality = 0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for vf in tqdm(video_files, desc='Extracting landmarks'):\n",
    "        vid = vf.stem\n",
    "        if vid not in meta_by_id:\n",
    "            skipped_missing += 1\n",
    "            continue\n",
    "        seq, dr = extract_video(vf)\n",
    "        if seq is None or dr < 0.30:   # strict: ‚â•30% detection\n",
    "            skipped_quality += 1\n",
    "            continue\n",
    "        X_list.append(seq)\n",
    "        y_list.append(meta_by_id[vid]['word_id'])\n",
    "\n",
    "    detector.close()\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list,  dtype=np.int32)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f'\\nüìä X: {X.shape} | y: {y.shape} | classes: {len(np.unique(y))}')\n",
    "    print(f'‚è±Ô∏è  {elapsed:.0f}s ({elapsed/60:.1f} min)')\n",
    "    print(f'   Skipped (not in vocab): {skipped_missing}')\n",
    "    print(f'   Skipped (low quality) : {skipped_quality}')\n",
    "\n",
    "    np.savez_compressed(NPZ_PATH, X=X, y=y)\n",
    "    print(f'üíæ Saved ‚Üí {NPZ_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77138963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 6: ADVANCED DATA EXPLORATION & QUALITY ANALYSIS\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üìä DATA EXPLORATION')\n",
    "print('=' * 65)\n",
    "\n",
    "if 'X' not in dir() or 'y' not in dir():\n",
    "    data = np.load(NPZ_PATH)\n",
    "    X, y = data['X'], data['y']\n",
    "\n",
    "unique_ids, counts = np.unique(y, return_counts=True)\n",
    "word_names = [id_to_english.get(int(uid), str(uid)) for uid in unique_ids]\n",
    "sort_idx   = np.argsort(counts)[::-1]\n",
    "s_names    = [word_names[i] for i in sort_idx]\n",
    "s_counts   = counts[sort_idx]\n",
    "\n",
    "# --- Plot 1: Class distribution ---\n",
    "fig, ax = plt.subplots(figsize=(26, 7))\n",
    "ax.bar(range(len(s_names)), s_counts, color='steelblue', edgecolor='navy', linewidth=0.3)\n",
    "ax.set_xticks(range(len(s_names)))\n",
    "ax.set_xticklabels(s_names, rotation=90, fontsize=5.5)\n",
    "ax.axhline(np.mean(s_counts),   color='red',    ls='--', alpha=0.7, label=f'Mean: {np.mean(s_counts):.1f}')\n",
    "ax.axhline(np.median(s_counts), color='orange', ls=':',  alpha=0.7, label=f'Median: {np.median(s_counts):.1f}')\n",
    "ax.set_title(f'Class Distribution ‚Äî {len(unique_ids)} classes, {len(y)} samples | seq={SEQUENCE_LENGTH}', fontsize=14)\n",
    "ax.set_xlabel('Word'); ax.set_ylabel('Samples'); ax.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Plot 2: Quality ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 5))\n",
    "axes[0].hist(s_counts, bins=25, color='steelblue', edgecolor='navy', alpha=0.85)\n",
    "axes[0].axvline(np.mean(s_counts), color='red', ls='--', label=f'Mean: {np.mean(s_counts):.1f}')\n",
    "axes[0].set_title('Samples per Class'); axes[0].legend()\n",
    "\n",
    "left_zero, right_zero, both_rate = [], [], []\n",
    "sample_n = min(len(X), 1000)\n",
    "for i in range(sample_n):\n",
    "    l_sum = np.sum(np.abs(X[i, :, :LANDMARKS_PER_HAND]), axis=1)\n",
    "    r_sum = np.sum(np.abs(X[i, :, LANDMARKS_PER_HAND:]), axis=1)\n",
    "    left_zero.append(np.sum(l_sum == 0) / SEQUENCE_LENGTH * 100)\n",
    "    right_zero.append(np.sum(r_sum == 0) / SEQUENCE_LENGTH * 100)\n",
    "    l_act = l_sum != 0;  r_act = r_sum != 0\n",
    "    both_rate.append(np.sum(l_act & r_act) / SEQUENCE_LENGTH * 100)\n",
    "\n",
    "axes[1].hist(left_zero,  bins=20, alpha=0.7, color='#2196F3', label='Left')\n",
    "axes[1].hist(right_zero, bins=20, alpha=0.7, color='#FF9800', label='Right')\n",
    "axes[1].set_title('Zero-Frame Rate per Hand'); axes[1].legend()\n",
    "\n",
    "axes[2].hist(both_rate, bins=20, color='#4CAF50', edgecolor='darkgreen', alpha=0.85)\n",
    "axes[2].set_title(f'Two-Hand Detection (mean: {np.mean(both_rate):.1f}%)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Plot 3: PCA of mean sequence per class ---\n",
    "if 'category' in vocab_df.columns:\n",
    "    cat_map = dict(zip(vocab_df['word_id'].astype(int), vocab_df['category']))\n",
    "    mean_vecs, cat_labels = [], []\n",
    "    for uid in unique_ids:\n",
    "        mask = y == uid\n",
    "        mean_vecs.append(X[mask].mean(axis=(0, 1)))\n",
    "        cat_labels.append(cat_map.get(int(uid), 'other'))\n",
    "    pca = PCA(n_components=2)\n",
    "    pts = pca.fit_transform(np.array(mean_vecs))\n",
    "    cats_unique = list(set(cat_labels))\n",
    "    cmap_pca = plt.cm.get_cmap('tab10', len(cats_unique))\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for ci, cat in enumerate(cats_unique):\n",
    "        mask = [c == cat for c in cat_labels]\n",
    "        ax.scatter(pts[mask, 0], pts[mask, 1], color=cmap_pca(ci), label=cat, s=30, alpha=0.7)\n",
    "    ax.set_title('PCA of Mean Landmark Vectors per Class (colored by category)', fontsize=13)\n",
    "    ax.legend(fontsize=9, ncol=2); ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "    ev = pca.explained_variance_ratio_\n",
    "    print(f'PCA explained variance: PC1={ev[0]*100:.1f}%  PC2={ev[1]*100:.1f}%')\n",
    "\n",
    "print(f'\\nüìä Summary:')\n",
    "print(f'   Total samples     : {len(y)}')\n",
    "print(f'   Classes           : {len(unique_ids)}')\n",
    "print(f'   Sequence length   : {SEQUENCE_LENGTH}')\n",
    "print(f'   Features/frame    : {NUM_FEATURES}')\n",
    "print(f'   Min samples/class : {counts.min()} ({word_names[counts.argmin()]})')\n",
    "print(f'   Max samples/class : {counts.max()} ({word_names[counts.argmax()]})')\n",
    "print(f'   Mean              : {counts.mean():.1f}')\n",
    "print(f'   Median            : {np.median(counts):.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79188ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 7: PREPROCESSING, AUGMENTATION & DATA SPLITS\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üîß PREPROCESSING & TRAIN/VAL/TEST SPLIT')\n",
    "print('=' * 65)\n",
    "\n",
    "# 1. Reload & normalize\n",
    "data = np.load(NPZ_PATH)\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "orig_shape  = X.shape\n",
    "X_flat      = X.reshape(-1, NUM_FEATURES)\n",
    "scaler      = StandardScaler()\n",
    "X_flat      = scaler.fit_transform(X_flat)\n",
    "X           = X_flat.reshape(orig_shape).astype(np.float32)\n",
    "joblib.dump(scaler, OUTPUT_DIR / 'scaler.pkl')\n",
    "print(f'  ‚úÖ StandardScaler fitted & saved  (shape: {X.shape})')\n",
    "\n",
    "# 2. Label encoding\n",
    "encoder     = LabelEncoder()\n",
    "y_encoded   = encoder.fit_transform(y)\n",
    "num_classes = len(encoder.classes_)\n",
    "y_onehot    = to_categorical(y_encoded, num_classes=num_classes)\n",
    "joblib.dump(encoder, OUTPUT_DIR / 'encoder.pkl')\n",
    "print(f'  ‚úÖ LabelEncoder saved  ({num_classes} classes)')\n",
    "\n",
    "# 3. Stratified 70/15/15 split\n",
    "try:\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_onehot, test_size=TEST_SIZE, random_state=42, stratify=y_encoded)\n",
    "    tl = np.argmax(y_temp, axis=1)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=tl)\n",
    "except ValueError:\n",
    "    print('  ‚ö†Ô∏è  Falling back to random split')\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_onehot, test_size=TEST_SIZE, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 4. Class weights (clipped 0.3‚Äì8.0 for extreme imbalance)\n",
    "train_lbl       = np.argmax(y_train, axis=1)\n",
    "present_cls     = np.unique(train_lbl)\n",
    "cw_vals         = compute_class_weight('balanced', classes=present_cls, y=train_lbl)\n",
    "cw_vals         = np.clip(cw_vals, 0.3, 8.0)\n",
    "class_weights   = {i: 1.0 for i in range(num_classes)}\n",
    "for i, ci in enumerate(present_cls):\n",
    "    class_weights[ci] = float(cw_vals[i])\n",
    "\n",
    "print(f'\\n  üìä Split:')\n",
    "print(f'     Classes     : {num_classes}')\n",
    "print(f'     Train       : {X_train.shape[0]:>6}  ({X_train.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'     Validation  : {X_val.shape[0]:>6}  ({X_val.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'     Test        : {X_test.shape[0]:>6}  ({X_test.shape[0]/len(X)*100:.0f}%)')\n",
    "print(f'     Input shape : {X_train.shape[1:]}')\n",
    "print(f'     Max CW      : {max(class_weights.values()):.2f}')\n",
    "\n",
    "# 5. Augmentation function (rich pipeline)\n",
    "@tf.function\n",
    "def augment_sequence(x, y_label):\n",
    "    \"\"\"\n",
    "    Heavy augmentation pipeline:\n",
    "    1. Gaussian noise (std=0.003)\n",
    "    2. Temporal shift ¬±5 frames\n",
    "    3. Frame dropout ~8%\n",
    "    4. Random scaling 0.8‚Äì1.2\n",
    "    5. Left/right hand swap (25% prob)\n",
    "    6. Speed perturbation (¬±20% via resize)\n",
    "    7. Wrist coordinate rotation ¬±15¬∞\n",
    "    \"\"\"\n",
    "    # 1. Noise\n",
    "    x = x + tf.random.normal(tf.shape(x), stddev=0.003)\n",
    "\n",
    "    # 2. Temporal shift\n",
    "    shift = tf.random.uniform([], -5, 6, dtype=tf.int32)\n",
    "    x = tf.roll(x, shift=shift, axis=0)\n",
    "\n",
    "    # 3. Frame dropout\n",
    "    mask = tf.cast(tf.random.uniform([SEQUENCE_LENGTH, 1]) > 0.08, tf.float32)\n",
    "    x = x * mask\n",
    "\n",
    "    # 4. Scale\n",
    "    scale = tf.random.uniform([], 0.80, 1.20)\n",
    "    x = x * scale\n",
    "\n",
    "    # 5. Hand swap\n",
    "    def swap_hands():\n",
    "        left  = x[:, :LANDMARKS_PER_HAND]\n",
    "        right = x[:, LANDMARKS_PER_HAND:]\n",
    "        return tf.concat([right, left], axis=1)\n",
    "    x = tf.cond(tf.random.uniform([]) < 0.25, swap_hands, lambda: x)\n",
    "\n",
    "    # 6. Speed perturbation ‚Äî squeeze/stretch the time axis\n",
    "    new_len = tf.cast(\n",
    "        tf.cast(SEQUENCE_LENGTH, tf.float32) * tf.random.uniform([], 0.80, 1.20),\n",
    "        tf.int32)\n",
    "    new_len = tf.clip_by_value(new_len, SEQUENCE_LENGTH // 2, SEQUENCE_LENGTH * 2)\n",
    "    x_exp   = tf.expand_dims(tf.expand_dims(x, 0), 3)     # (1, T, F, 1)\n",
    "    x_res   = tf.image.resize(x_exp, [new_len, NUM_FEATURES])  # resize along time\n",
    "    x_res   = tf.squeeze(x_res, axis=[0, 3])               # (new_len, F)\n",
    "    # Resample back to SEQUENCE_LENGTH\n",
    "    indices = tf.cast(\n",
    "        tf.linspace(0.0, tf.cast(new_len - 1, tf.float32), SEQUENCE_LENGTH), tf.int32)\n",
    "    x = tf.gather(x_res, indices)\n",
    "\n",
    "    # 7. In-plane rotation of x/y coords (first 2 of every 3 features)\n",
    "    theta = tf.random.uniform([], -math.pi/12, math.pi/12)   # ¬±15¬∞\n",
    "    cos_t = tf.cos(theta);  sin_t = tf.sin(theta)\n",
    "    # reshape into (T, num_pts, 3) and rotate x,y\n",
    "    num_pts = NUM_FEATURES // 3\n",
    "    x3 = tf.reshape(x, [SEQUENCE_LENGTH, num_pts, 3])\n",
    "    xs, ys, zs = x3[:, :, 0], x3[:, :, 1], x3[:, :, 2]\n",
    "    xr = xs * cos_t - ys * sin_t\n",
    "    yr = xs * sin_t + ys * cos_t\n",
    "    x3 = tf.stack([xr, yr, zs], axis=2)\n",
    "    x  = tf.reshape(x3, [SEQUENCE_LENGTH, NUM_FEATURES])\n",
    "\n",
    "    return x, y_label\n",
    "\n",
    "print('  ‚úÖ Augmentation pipeline defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7937fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 8: CUSTOM ARCHITECTURE ‚Äî CNN-BiLSTM + TRANSFORMER + ATTENTION\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üèóÔ∏è  BUILDING CNN-BiLSTM + TRANSFORMER ENSEMBLE BACKBONE')\n",
    "print('=' * 65)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Custom Layers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"Transformer encoder block: Multi-Head Self-Attention + FFN + residual.\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attn  = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads,\n",
    "                                         dropout=dropout)\n",
    "        self.ffn1  = Dense(ff_dim,    activation='gelu')\n",
    "        self.ffn2  = Dense(embed_dim)\n",
    "        self.ln1   = LayerNormalization(epsilon=1e-6)\n",
    "        self.ln2   = LayerNormalization(epsilon=1e-6)\n",
    "        self.drop1 = Dropout(dropout)\n",
    "        self.drop2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        attn_out = self.attn(x, x, training=training)\n",
    "        attn_out = self.drop1(attn_out, training=training)\n",
    "        x = self.ln1(x + attn_out)\n",
    "        ffn_out = self.ffn2(self.ffn1(x))\n",
    "        ffn_out = self.drop2(ffn_out, training=training)\n",
    "        return self.ln2(x + ffn_out)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update(dict(\n",
    "            embed_dim=self.ffn2.units,\n",
    "            num_heads=self.attn.num_heads,\n",
    "            ff_dim=self.ffn1.units,\n",
    "            dropout=self.drop1.rate\n",
    "        ))\n",
    "        return cfg\n",
    "\n",
    "\n",
    "class TemporalAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"Weighted temporal pooling over the time axis.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight('W', shape=(input_shape[-1], 1),\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b = self.add_weight('b', shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',          trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.nn.tanh(tf.matmul(x, self.W) + self.b)   # (B, T, 1)\n",
    "        a = tf.nn.softmax(e, axis=1)                     # (B, T, 1)\n",
    "        return tf.reduce_sum(x * a, axis=1)              # (B, F)\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Model Builder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def build_main_model(seq_len, num_feat, n_classes):\n",
    "    \"\"\"\n",
    "    CNN-BiLSTM + Transformer Encoder + Temporal Attention\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    Stage 1: Local motion extractor  (Conv1D √ó3)\n",
    "    Stage 2: Temporal sequence model (Bi-LSTM √ó3)\n",
    "    Stage 3: Global context          (Transformer blocks √ó3)\n",
    "    Stage 4: Attention pooling\n",
    "    Stage 5: Dense classifier head\n",
    "    \"\"\"\n",
    "    reg = tf.keras.regularizers.l2(L2_REG)\n",
    "    inp = Input(shape=(seq_len, num_feat), name='landmarks')\n",
    "\n",
    "    # ‚îÄ‚îÄ Conv1D feature extractor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    x = Conv1D(CNN_FILTERS_1, 3, padding='same', use_bias=False)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('gelu')(x)\n",
    "\n",
    "    x = Conv1D(CNN_FILTERS_2, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('gelu')(x)\n",
    "\n",
    "    x = Conv1D(CNN_FILTERS_3, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('gelu')(x)\n",
    "\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)\n",
    "\n",
    "    # ‚îÄ‚îÄ BiLSTM stack ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    x = Bidirectional(LSTM(LSTM_UNITS_1, return_sequences=True,\n",
    "                           recurrent_dropout=0.0,\n",
    "                           kernel_regularizer=reg), name='bilstm_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(LSTM_UNITS_2, return_sequences=True,\n",
    "                           kernel_regularizer=reg), name='bilstm_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(LSTM_UNITS_3, return_sequences=True,\n",
    "                           kernel_regularizer=reg), name='bilstm_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # ‚îÄ‚îÄ Transformer encoder blocks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    embed_dim = x.shape[-1]   # 2 √ó LSTM_UNITS_3 (bidirectional)\n",
    "    for i in range(NUM_TRANSFORMER_BLOCKS):\n",
    "        x = TransformerBlock(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=NUM_TRANSFORMER_HEADS,\n",
    "            ff_dim=TRANSFORMER_FF_DIM,\n",
    "            dropout=DROPOUT_RATE * 0.5,\n",
    "            name=f'transformer_{i}'\n",
    "        )(x)\n",
    "\n",
    "    # ‚îÄ‚îÄ Attention pooling ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    x = TemporalAttention(name='temporal_attention')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "    # ‚îÄ‚îÄ Dense head ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    x = Dense(DENSE_UNITS, use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('gelu')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "    x = Dense(DENSE_UNITS // 2, use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('gelu')(x)\n",
    "    x = Dropout(DROPOUT_RATE * 0.5)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', dtype='float32', name='output')(x)\n",
    "\n",
    "    return Model(inp, out, name='ASL_CNN_BiLSTM_Transformer_V2')\n",
    "\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    main_model = build_main_model(SEQUENCE_LENGTH, NUM_FEATURES, num_classes)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Focal loss ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Manually implemented so it works on all TF versions\n",
    "def categorical_focal_loss(gamma=2.0, label_smoothing=LABEL_SMOOTH):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred  = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
    "        # Label smoothing\n",
    "        n_cls   = tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "        y_true  = y_true * (1 - label_smoothing) + label_smoothing / n_cls\n",
    "        ce      = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "        p_t     = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        focal_w = tf.pow(1.0 - p_t, gamma)\n",
    "        return tf.reduce_mean(focal_w * ce)\n",
    "    return loss_fn\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ AdamW optimizer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        clipnorm=GRAD_CLIP_NORM\n",
    "    )\n",
    "    print('  ‚úÖ Using AdamW optimizer')\n",
    "except AttributeError:\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        clipnorm=GRAD_CLIP_NORM\n",
    "    )\n",
    "    print('  ‚ÑπÔ∏è  AdamW not available ‚Äî falling back to Adam')\n",
    "\n",
    "# Top-5 accuracy metric\n",
    "top5_metric = tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')\n",
    "\n",
    "main_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=categorical_focal_loss(gamma=FOCAL_GAMMA),\n",
    "    metrics=['accuracy', top5_metric]\n",
    ")\n",
    "\n",
    "print('\\nüìê Architecture:')\n",
    "main_model.summary()\n",
    "print(f'\\n  Input : ({SEQUENCE_LENGTH} frames, {NUM_FEATURES} features)')\n",
    "print(f'  Output: {num_classes} classes')\n",
    "total_params = main_model.count_params()\n",
    "print(f'  Params: {total_params:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd06697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 9: TRAINING PIPELINE WITH COSINE WARMUP LR SCHEDULE\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üöÄ TRAINING ‚Äî CosineDecay + Warmup | Focal Loss | AdamW')\n",
    "print('=' * 65)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ tf.data pipelines ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "            .shuffle(min(len(X_train), 15000), reshuffle_each_iteration=True)\n",
    "            .map(augment_sequence, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTOTUNE))\n",
    "\n",
    "val_ds  = (tf.data.Dataset.from_tensor_slices((X_val,  y_val))\n",
    "           .batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "test_ds = (tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "           .batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "\n",
    "print(f'  ‚úÖ tf.data pipelines ready  (batch={BATCH_SIZE})')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Cosine Decay with Linear Warmup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class CosineWarmupSchedule(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Linear warmup for `warmup_epochs`, then cosine decay to `min_lr`.\"\"\"\n",
    "    def __init__(self, total_epochs, warmup_epochs, base_lr, min_lr=1e-7):\n",
    "        super().__init__()\n",
    "        self.total   = total_epochs\n",
    "        self.warmup  = warmup_epochs\n",
    "        self.base_lr = base_lr\n",
    "        self.min_lr  = min_lr\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch < self.warmup:\n",
    "            lr = self.base_lr * (epoch + 1) / self.warmup\n",
    "        else:\n",
    "            decay_steps = self.total - self.warmup\n",
    "            step        = epoch - self.warmup\n",
    "            cos_decay   = 0.5 * (1 + math.cos(math.pi * step / decay_steps))\n",
    "            lr = self.min_lr + (self.base_lr - self.min_lr) * cos_decay\n",
    "        tf.keras.backend.set_value(self.model.optimizer.learning_rate, lr)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Callbacks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        str(OUTPUT_DIR / 'asl_word_lstm_v2_best.h5'),\n",
    "        monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', patience=40, restore_best_weights=True, verbose=1\n",
    "    ),\n",
    "    CosineWarmupSchedule(\n",
    "        total_epochs=EPOCHS, warmup_epochs=WARMUP_EPOCHS,\n",
    "        base_lr=LEARNING_RATE, min_lr=1e-7\n",
    "    ),\n",
    "    CSVLogger(str(OUTPUT_DIR / 'training_log_v2.csv')),\n",
    "    TerminateOnNaN(),\n",
    "]\n",
    "\n",
    "# TensorBoard (optional ‚Äî works on Kaggle too)\n",
    "try:\n",
    "    tb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=str(OUTPUT_DIR / 'tb_logs'), histogram_freq=0, update_freq='epoch')\n",
    "    callbacks.append(tb)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f'  ‚úÖ Callbacks ready  (patience=40, warmup={WARMUP_EPOCHS}ep)')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Train ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f'\\nüöÄ Training on {DEVICE} | {EPOCHS} epochs | bs={BATCH_SIZE}')\n",
    "print(f'   LR: {LEARNING_RATE} ‚Üí warmup {WARMUP_EPOCHS}ep ‚Üí cosine ‚Üí 1e-7')\n",
    "print(f'   Focal Œ≥={FOCAL_GAMMA} | label_smooth={LABEL_SMOOTH} | grad_clip={GRAD_CLIP_NORM}')\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.device(DEVICE):\n",
    "    history = main_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "elapsed = time.time() - t0\n",
    "best_epoch = int(np.argmax(history.history['val_accuracy'])) + 1\n",
    "best_val   = max(history.history['val_accuracy'])\n",
    "print(f'\\n‚úÖ Training done in {elapsed:.0f}s ({elapsed/60:.1f} min)')\n",
    "print(f'   Best epoch     : {best_epoch}')\n",
    "print(f'   Best val_acc   : {best_val*100:.2f}%')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Save final model + class mapping ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "main_model.save(str(OUTPUT_DIR / 'asl_word_lstm_v2_final.h5'))\n",
    "class_df = pd.DataFrame({\n",
    "    'model_class_index': range(num_classes),\n",
    "    'word_id':           encoder.classes_.tolist()\n",
    "})\n",
    "class_df['english'] = class_df['word_id'].map(id_to_english)\n",
    "class_df.to_csv(OUTPUT_DIR / 'asl_word_classes_v2.csv', index=False)\n",
    "print(f'\\nüíæ Saved final model & class CSV ‚Üí {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 10: ENSEMBLE ‚Äî PURE TRANSFORMER + TCN + CNN-BiLSTM\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üé≠ BUILDING & TRAINING ENSEMBLE (Transformer + TCN + main)')\n",
    "print('=' * 65)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Model 2: Pure Transformer Encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def build_transformer_model(seq_len, num_feat, n_classes,\n",
    "                              num_blocks=4, num_heads=8, ff_dim=512,\n",
    "                              embed_dim=256, dropout=0.3):\n",
    "    reg = tf.keras.regularizers.l2(L2_REG)\n",
    "    inp = Input(shape=(seq_len, num_feat))\n",
    "\n",
    "    # Project input to embed_dim\n",
    "    x = Dense(embed_dim, use_bias=False)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Learnable positional embeddings\n",
    "    positions = tf.range(start=0, limit=seq_len, delta=1)\n",
    "    pos_emb   = tf.keras.layers.Embedding(seq_len, embed_dim)(positions)\n",
    "    x = x + pos_emb\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim, dropout, name=f'tb_{i}')(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dense(512, use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = BatchNormalization()(x); x = tf.keras.layers.Activation('gelu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    out = Dense(n_classes, activation='softmax', dtype='float32')(x)\n",
    "    return Model(inp, out, name='ASL_PureTransformer')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Model 3: TCN (Temporal Conv Network with dilations) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def build_tcn_model(seq_len, num_feat, n_classes,\n",
    "                     filters=256, kernel_size=3, dilations=(1,2,4,8,16), dropout=0.3):\n",
    "    reg = tf.keras.regularizers.l2(L2_REG)\n",
    "    inp = Input(shape=(seq_len, num_feat))\n",
    "    x   = Conv1D(filters, 1, padding='causal', use_bias=False)(inp)\n",
    "    x   = BatchNormalization()(x)\n",
    "\n",
    "    for d in dilations:\n",
    "        res = x\n",
    "        x   = Conv1D(filters, kernel_size, dilation_rate=d, padding='causal',\n",
    "                     use_bias=False, kernel_regularizer=reg)(x)\n",
    "        x   = BatchNormalization()(x); x = tf.keras.layers.Activation('gelu')(x)\n",
    "        x   = SpatialDropout1D(dropout)(x)\n",
    "        x   = Conv1D(filters, kernel_size, dilation_rate=d, padding='causal',\n",
    "                     use_bias=False, kernel_regularizer=reg)(x)\n",
    "        x   = BatchNormalization()(x); x = tf.keras.layers.Activation('gelu')(x)\n",
    "        # Residual (match channels)\n",
    "        if res.shape[-1] != filters:\n",
    "            res = Conv1D(filters, 1, padding='same', use_bias=False)(res)\n",
    "        x = Add()([x, res])\n",
    "\n",
    "    x   = GlobalAveragePooling1D()(x)\n",
    "    x   = Dense(512, use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x   = BatchNormalization()(x); x = tf.keras.layers.Activation('gelu')(x)\n",
    "    x   = Dropout(dropout)(x)\n",
    "    out = Dense(n_classes, activation='softmax', dtype='float32')(x)\n",
    "    return Model(inp, out, name='ASL_TCN')\n",
    "\n",
    "# Instantiate & compile sub-models\n",
    "print('  Building Transformer model...')\n",
    "try:\n",
    "    opt2 = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE,\n",
    "                                      weight_decay=WEIGHT_DECAY, clipnorm=GRAD_CLIP_NORM)\n",
    "except AttributeError:\n",
    "    opt2 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=GRAD_CLIP_NORM)\n",
    "\n",
    "transformer_model = build_transformer_model(SEQUENCE_LENGTH, NUM_FEATURES, num_classes)\n",
    "transformer_model.compile(optimizer=opt2,\n",
    "                           loss=categorical_focal_loss(gamma=FOCAL_GAMMA),\n",
    "                           metrics=['accuracy', top5_metric])\n",
    "\n",
    "print('  Building TCN model...')\n",
    "try:\n",
    "    opt3 = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE,\n",
    "                                      weight_decay=WEIGHT_DECAY, clipnorm=GRAD_CLIP_NORM)\n",
    "except AttributeError:\n",
    "    opt3 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=GRAD_CLIP_NORM)\n",
    "\n",
    "tcn_model = build_tcn_model(SEQUENCE_LENGTH, NUM_FEATURES, num_classes)\n",
    "tcn_model.compile(optimizer=opt3,\n",
    "                   loss=categorical_focal_loss(gamma=FOCAL_GAMMA),\n",
    "                   metrics=['accuracy', top5_metric])\n",
    "\n",
    "print(f'  Transformer params : {transformer_model.count_params():,}')\n",
    "print(f'  TCN params         : {tcn_model.count_params():,}')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Train sub-models ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "sub_cbs_1 = [\n",
    "    ModelCheckpoint(str(OUTPUT_DIR / 'transformer_best.h5'),\n",
    "                    monitor='val_accuracy', save_best_only=True, mode='max', verbose=0),\n",
    "    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=0),\n",
    "    CosineWarmupSchedule(EPOCHS, WARMUP_EPOCHS, LEARNING_RATE),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "sub_cbs_2 = [\n",
    "    ModelCheckpoint(str(OUTPUT_DIR / 'tcn_best.h5'),\n",
    "                    monitor='val_accuracy', save_best_only=True, mode='max', verbose=0),\n",
    "    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=0),\n",
    "    CosineWarmupSchedule(EPOCHS, WARMUP_EPOCHS, LEARNING_RATE),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "print('\\nüöÄ Training Transformer sub-model...')\n",
    "with tf.device(DEVICE):\n",
    "    hist_t = transformer_model.fit(train_ds, validation_data=val_ds,\n",
    "                                    epochs=EPOCHS, callbacks=sub_cbs_1,\n",
    "                                    class_weight=class_weights, verbose=0)\n",
    "best_t = max(hist_t.history['val_accuracy'])\n",
    "print(f'   ‚úÖ Best val_acc (Transformer): {best_t*100:.2f}%')\n",
    "\n",
    "print('\\nüöÄ Training TCN sub-model...')\n",
    "with tf.device(DEVICE):\n",
    "    hist_tc = tcn_model.fit(train_ds, validation_data=val_ds,\n",
    "                             epochs=EPOCHS, callbacks=sub_cbs_2,\n",
    "                             class_weight=class_weights, verbose=0)\n",
    "best_tc = max(hist_tc.history['val_accuracy'])\n",
    "print(f'   ‚úÖ Best val_acc (TCN): {best_tc*100:.2f}%')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Build learned-weight ensemble ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('\\nüîó Building learned ensemble...')\n",
    "\n",
    "inp_ens = Input(shape=(SEQUENCE_LENGTH, NUM_FEATURES), name='ensemble_input')\n",
    "\n",
    "# Use best checkpoints\n",
    "main_loaded = tf.keras.models.load_model(\n",
    "    str(OUTPUT_DIR / 'asl_word_lstm_v2_best.h5'),\n",
    "    custom_objects={'TransformerBlock': TransformerBlock,\n",
    "                    'TemporalAttention': TemporalAttention,\n",
    "                    'loss_fn': categorical_focal_loss(FOCAL_GAMMA)},\n",
    "    compile=False\n",
    ")\n",
    "trans_loaded = tf.keras.models.load_model(\n",
    "    str(OUTPUT_DIR / 'transformer_best.h5'),\n",
    "    custom_objects={'TransformerBlock': TransformerBlock,\n",
    "                    'loss_fn': categorical_focal_loss(FOCAL_GAMMA)},\n",
    "    compile=False\n",
    ")\n",
    "tcn_loaded = tf.keras.models.load_model(\n",
    "    str(OUTPUT_DIR / 'tcn_best.h5'),\n",
    "    custom_objects={'loss_fn': categorical_focal_loss(FOCAL_GAMMA)},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Freeze backbone weights ‚Äî only train the ensemble head\n",
    "for m in [main_loaded, trans_loaded, tcn_loaded]:\n",
    "    m.trainable = False\n",
    "\n",
    "p1 = main_loaded(inp_ens)\n",
    "p2 = trans_loaded(inp_ens)\n",
    "p3 = tcn_loaded(inp_ens)\n",
    "\n",
    "# Learnable softmax scalar weights\n",
    "ens_raw    = tf.keras.layers.Concatenate(axis=-1)([\n",
    "    tf.keras.layers.Reshape((num_classes, 1))(p1),\n",
    "    tf.keras.layers.Reshape((num_classes, 1))(p2),\n",
    "    tf.keras.layers.Reshape((num_classes, 1))(p3),\n",
    "])   # (B, num_classes, 3)\n",
    "w_logits   = tf.keras.layers.Dense(1, use_bias=False,\n",
    "                                    kernel_initializer='ones')(ens_raw)  # (B, C, 1)\n",
    "w_logits   = tf.keras.layers.Lambda(lambda x: tf.squeeze(x, -1))(w_logits)\n",
    "ens_out    = tf.keras.layers.Softmax(axis=-1)(w_logits)\n",
    "\n",
    "ensemble_model = Model(inp_ens, ens_out, name='ASL_Ensemble')\n",
    "try:\n",
    "    opt_ens = tf.keras.optimizers.AdamW(learning_rate=1e-4,\n",
    "                                         weight_decay=1e-5, clipnorm=1.0)\n",
    "except AttributeError:\n",
    "    opt_ens = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=opt_ens,\n",
    "    loss=categorical_focal_loss(FOCAL_GAMMA),\n",
    "    metrics=['accuracy', top5_metric]\n",
    ")\n",
    "\n",
    "print('  Fine-tuning ensemble head (20 epochs)...')\n",
    "with tf.device(DEVICE):\n",
    "    hist_ens = ensemble_model.fit(\n",
    "        train_ds, validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True, verbose=0),\n",
    "                   TerminateOnNaN()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "ensemble_model.save(str(OUTPUT_DIR / 'asl_word_ensemble_final.h5'))\n",
    "best_ens_val = max(hist_ens.history['val_accuracy'])\n",
    "print(f'\\n‚úÖ Ensemble val_acc : {best_ens_val*100:.2f}%')\n",
    "print(f'üíæ Saved ‚Üí {OUTPUT_DIR / \"asl_word_ensemble_final.h5\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa719e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 11: COMPREHENSIVE EVALUATION DASHBOARD\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üìà EVALUATION DASHBOARD  (Ensemble Model)')\n",
    "print('=' * 65)\n",
    "\n",
    "word_labels = [id_to_english.get(int(encoder.classes_[i]), str(encoder.classes_[i]))\n",
    "               for i in range(num_classes)]\n",
    "\n",
    "# ‚îÄ‚îÄ Predictions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "eval_ds = (tf.data.Dataset.from_tensor_slices((X_test,))\n",
    "           .batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    proba = ensemble_model.predict(eval_ds, verbose=0)\n",
    "\n",
    "y_pred = np.argmax(proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# ‚îÄ‚îÄ Top-K Accuracy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def topk_acc(proba, y_true, k):\n",
    "    correct = sum(1 for i in range(len(y_true))\n",
    "                  if y_true[i] in np.argsort(proba[i])[-k:])\n",
    "    return correct / len(y_true)\n",
    "\n",
    "top1 = (y_pred == y_true).mean()\n",
    "top3 = topk_acc(proba, y_true, 3)\n",
    "top5 = topk_acc(proba, y_true, 5)\n",
    "\n",
    "print(f'\\nüéØ Ensemble Test Results:')\n",
    "print(f'   Top-1 : {top1*100:.2f}%')\n",
    "print(f'   Top-3 : {top3*100:.2f}%')\n",
    "print(f'   Top-5 : {top5*100:.2f}%')\n",
    "print(f'   N test: {len(y_true)}  | classes: {num_classes}')\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 1: Training Dashboard (main model) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "h = history.history\n",
    "\n",
    "axes[0,0].plot(h['accuracy'],     lw=2, color='#2196F3', label='Train')\n",
    "axes[0,0].plot(h['val_accuracy'], lw=2, color='#FF9800', label='Val')\n",
    "best_ep = int(np.argmax(h['val_accuracy']))\n",
    "axes[0,0].axvline(best_ep, color='green', ls=':', alpha=0.6, label=f'Best ep {best_ep+1}')\n",
    "axes[0,0].fill_between(range(len(h['accuracy'])), h['accuracy'], h['val_accuracy'],\n",
    "                        alpha=0.08, color='red')\n",
    "axes[0,0].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylim([0, 1.05]); axes[0,0].legend(); axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "axes[0,1].plot(h['loss'],     lw=2, color='#2196F3', label='Train')\n",
    "axes[0,1].plot(h['val_loss'], lw=2, color='#FF9800', label='Val')\n",
    "axes[0,1].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0,1].legend(); axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "lr_vals = h.get('lr', [LEARNING_RATE] * len(h['loss']))\n",
    "axes[1,0].plot(lr_vals, lw=2, color='#4CAF50', marker='o', markersize=3)\n",
    "axes[1,0].set_yscale('log'); axes[1,0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1,0].grid(alpha=0.3)\n",
    "\n",
    "gap = np.array(h['accuracy']) - np.array(h['val_accuracy'])\n",
    "bar_colors = ['green' if g < 0.05 else 'orange' if g < 0.15 else 'red' for g in gap]\n",
    "axes[1,1].bar(range(len(gap)), gap, color=bar_colors, alpha=0.8, linewidth=0.3, edgecolor='black')\n",
    "axes[1,1].axhline(0.05, color='green', ls='--', alpha=0.5, label='Healthy (5%)')\n",
    "axes[1,1].axhline(0.15, color='red',   ls='--', alpha=0.5, label='Overfit (15%)')\n",
    "axes[1,1].set_title('Overfitting Monitor', fontsize=14, fontweight='bold')\n",
    "axes[1,1].legend(); axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'CNN-BiLSTM+Transformer V2 | Top-1: {top1*100:.1f}%  Top-5: {top5*100:.1f}%',\n",
    "             fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 2: Confidence distribution ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "correct_mask = y_pred == y_true\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axes[0].hist(np.max(proba[correct_mask],  axis=1), bins=30, alpha=0.7,\n",
    "             color='#4CAF50', edgecolor='darkgreen', label=f'Correct ({correct_mask.sum()})')\n",
    "if (~correct_mask).sum() > 0:\n",
    "    axes[0].hist(np.max(proba[~correct_mask], axis=1), bins=30, alpha=0.7,\n",
    "                 color='#F44336', edgecolor='darkred', label=f'Wrong ({(~correct_mask).sum()})')\n",
    "axes[0].set_title('Confidence: Correct vs Wrong'); axes[0].legend()\n",
    "sorted_p = np.sort(proba, axis=1)[:, ::-1]\n",
    "margin   = sorted_p[:, 0] - sorted_p[:, 1]\n",
    "axes[1].hist(margin, bins=30, color='#9C27B0', edgecolor='purple', alpha=0.8)\n",
    "axes[1].set_title(f'Decision Margin (mean={np.mean(margin):.3f})')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ Classification Report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('\\nüìã Classification Report:')\n",
    "report = classification_report(y_true, y_pred, labels=range(num_classes),\n",
    "                                target_names=word_labels, zero_division=0, output_dict=True)\n",
    "print(classification_report(y_true, y_pred, labels=range(num_classes),\n",
    "                             target_names=word_labels, zero_division=0))\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 3: Per-class F1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class_f1 = {w: report[w]['f1-score'] for w in word_labels if w in report}\n",
    "sf1 = sorted(class_f1.items(), key=lambda x: x[1], reverse=True)\n",
    "fig, ax = plt.subplots(figsize=(26, 6))\n",
    "f1_cols = ['#4CAF50' if v >= 0.7 else '#FF9800' if v >= 0.4 else '#F44336'\n",
    "           for _, v in sf1]\n",
    "ax.bar(range(len(sf1)), [v for _, v in sf1], color=f1_cols, edgecolor='black', lw=0.3)\n",
    "ax.set_xticks(range(len(sf1)))\n",
    "ax.set_xticklabels([n for n, _ in sf1], rotation=90, fontsize=5.5)\n",
    "mean_f1 = np.mean([v for _, v in sf1])\n",
    "ax.axhline(mean_f1, color='blue', ls='--', alpha=0.5, label=f'Mean F1: {mean_f1:.3f}')\n",
    "ax.set_title(f'Per-Class F1 Score ‚Äî Mean: {mean_f1:.3f}', fontsize=14)\n",
    "ax.set_ylim([0, 1.05]); ax.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 4: Normalized confusion matrix ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
    "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-9)\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "sns.heatmap(cm_norm, cmap='Blues', ax=ax,\n",
    "            xticklabels=word_labels, yticklabels=word_labels,\n",
    "            annot=(num_classes <= 50), fmt='.2f' if num_classes <= 50 else '')\n",
    "ax.set_title(f'Normalized Confusion Matrix | Top-1: {top1*100:.1f}%', fontsize=15)\n",
    "ax.set_xlabel('Predicted', fontsize=13); ax.set_ylabel('True', fontsize=13)\n",
    "plt.xticks(rotation=90, fontsize=5); plt.yticks(fontsize=5)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 5: Top-15 confused pairs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cm_off = cm.copy(); np.fill_diagonal(cm_off, 0)\n",
    "pairs = [(word_labels[i], word_labels[j], cm_off[i, j])\n",
    "         for i in range(num_classes) for j in range(num_classes) if cm_off[i, j] > 0]\n",
    "pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "top15 = pairs[:15]\n",
    "if top15:\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    labels15 = [f'{a} ‚Üí {b}' for a, b, _ in top15]\n",
    "    vals15   = [c for _, _, c in top15]\n",
    "    bars = ax.barh(range(len(labels15)), vals15, color='#E91E63', edgecolor='darkred', alpha=0.85)\n",
    "    ax.set_yticks(range(len(labels15))); ax.set_yticklabels(labels15, fontsize=9)\n",
    "    ax.invert_yaxis()\n",
    "    for bar, v in zip(bars, vals15):\n",
    "        ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "                str(v), va='center', fontsize=9, fontweight='bold')\n",
    "    ax.set_title('Top-15 Most Confused Pairs', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 6: Per-category accuracy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if 'category' in vocab_df.columns:\n",
    "    cat_map = dict(zip(vocab_df['word_id'].astype(int), vocab_df['category']))\n",
    "    cat_ok, cat_tot = {}, {}\n",
    "    for i in range(len(y_true)):\n",
    "        wid = int(encoder.classes_[y_true[i]])\n",
    "        cat = cat_map.get(wid, 'other')\n",
    "        cat_tot[cat] = cat_tot.get(cat, 0) + 1\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            cat_ok[cat] = cat_ok.get(cat, 0) + 1\n",
    "    cats = sorted(cat_tot)\n",
    "    cat_accs = [cat_ok.get(c, 0) / cat_tot[c] for c in cats]\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    bars = ax.bar(range(len(cats)), [a*100 for a in cat_accs],\n",
    "                  color='#2196F3', edgecolor='navy', alpha=0.85)\n",
    "    ax.set_xticks(range(len(cats))); ax.set_xticklabels(cats, rotation=45, ha='right')\n",
    "    for bar, acc, cat in zip(bars, cat_accs, cats):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{acc*100:.1f}%\\n(n={cat_tot[cat]})', ha='center', fontsize=8, fontweight='bold')\n",
    "    ax.axhline(top1*100, color='red', ls='--', alpha=0.5, label=f'Overall: {top1*100:.1f}%')\n",
    "    ax.set_ylim([0, 110]); ax.set_title('Per-Category Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 7: Best vs Worst 10 classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "pcacc = {}\n",
    "for i in range(num_classes):\n",
    "    m = y_true == i\n",
    "    if m.sum() > 0:\n",
    "        pcacc[word_labels[i]] = (y_pred[m] == i).mean()\n",
    "sorted_pc = sorted(pcacc.items(), key=lambda x: x[1])\n",
    "n_show = min(10, len(sorted_pc))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "worst = sorted_pc[:n_show]\n",
    "ax1.barh(range(n_show), [w[1]*100 for w in worst], color='#F44336', alpha=0.85, edgecolor='darkred')\n",
    "ax1.set_yticks(range(n_show)); ax1.set_yticklabels([w[0] for w in worst])\n",
    "ax1.set_xlabel('Accuracy (%)'); ax1.set_title(f'Bottom {n_show}', fontsize=14, color='#F44336')\n",
    "for i, w in enumerate(worst):\n",
    "    ax1.text(w[1]*100 + 0.5, i, f'{w[1]*100:.1f}%', va='center')\n",
    "best = sorted_pc[-n_show:][::-1]\n",
    "ax2.barh(range(n_show), [b[1]*100 for b in best], color='#4CAF50', alpha=0.85, edgecolor='darkgreen')\n",
    "ax2.set_yticks(range(n_show)); ax2.set_yticklabels([b[0] for b in best])\n",
    "ax2.set_xlabel('Accuracy (%)'); ax2.set_title(f'Top {n_show}', fontsize=14, color='#4CAF50')\n",
    "for i, b in enumerate(best):\n",
    "    ax2.text(b[1]*100 + 0.5, i, f'{b[1]*100:.1f}%', va='center')\n",
    "plt.suptitle('Best vs Worst Classes ‚Äî Ensemble', fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ‚îÄ‚îÄ PLOT 8: Precision-Recall scatter (F1 color) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "precs = [report[w]['precision']  for w in word_labels if w in report]\n",
    "recs  = [report[w]['recall']     for w in word_labels if w in report]\n",
    "f1s   = [report[w]['f1-score']   for w in word_labels if w in report]\n",
    "wl_r  = [w for w in word_labels if w in report]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sc = ax.scatter(recs, precs, c=f1s, cmap='RdYlGn', s=55, edgecolors='black', lw=0.5, alpha=0.85)\n",
    "plt.colorbar(sc, label='F1 Score', ax=ax)\n",
    "ax.set_xlabel('Recall', fontsize=13); ax.set_ylabel('Precision', fontsize=13)\n",
    "ax.set_title('Precision vs Recall (color = F1)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([-0.05, 1.05]); ax.set_ylim([-0.05, 1.05])\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.2); ax.grid(alpha=0.3)\n",
    "for i, lbl in enumerate(wl_r):\n",
    "    if f1s[i] < 0.3:\n",
    "        ax.annotate(lbl, (recs[i], precs[i]), fontsize=7, alpha=0.8, xytext=(4, 4),\n",
    "                    textcoords='offset points')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print('\\n' + '=' * 65)\n",
    "print(f'‚úÖ FINAL RESULTS')\n",
    "print(f'   Top-1 : {top1*100:.2f}%')\n",
    "print(f'   Top-3 : {top3*100:.2f}%')\n",
    "print(f'   Top-5 : {top5*100:.2f}%')\n",
    "print('=' * 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# CELL 12: EXPORT ARTIFACTS & DOWNLOAD\n",
    "# ===============================================================\n",
    "print('=' * 65)\n",
    "print('üíæ EXPORT ARTIFACTS')\n",
    "print('=' * 65)\n",
    "\n",
    "# Confirm all files are saved\n",
    "artifacts = {\n",
    "    'Best CNN-BiLSTM model'   : OUTPUT_DIR / 'asl_word_lstm_v2_best.h5',\n",
    "    'Final CNN-BiLSTM model'  : OUTPUT_DIR / 'asl_word_lstm_v2_final.h5',\n",
    "    'Transformer sub-model'   : OUTPUT_DIR / 'transformer_best.h5',\n",
    "    'TCN sub-model'           : OUTPUT_DIR / 'tcn_best.h5',\n",
    "    'Ensemble model'          : OUTPUT_DIR / 'asl_word_ensemble_final.h5',\n",
    "    'Scaler (sklearn)'        : OUTPUT_DIR / 'scaler.pkl',\n",
    "    'Label encoder (sklearn)' : OUTPUT_DIR / 'encoder.pkl',\n",
    "    'Class mapping CSV'       : OUTPUT_DIR / 'asl_word_classes_v2.csv',\n",
    "    'Training log CSV'        : OUTPUT_DIR / 'training_log_v2.csv',\n",
    "    'Sequence dataset'        : NPZ_PATH,\n",
    "}\n",
    "\n",
    "print('\\nFile inventory:')\n",
    "total_mb = 0.0\n",
    "for desc, path in artifacts.items():\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        mb = p.stat().st_size / (1024 * 1024)\n",
    "        total_mb += mb\n",
    "        print(f'  ‚úÖ  {p.name:<42}  {mb:7.1f} MB   [{desc}]')\n",
    "    else:\n",
    "        print(f'  ‚ùå  {str(p.name):<42}  NOT FOUND  [{desc}]')\n",
    "\n",
    "print(f'\\n  Total   : {total_mb:.1f} MB')\n",
    "print(f'  Location: {OUTPUT_DIR}')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print('\\nüí° Kaggle: go to Output tab and click ‚ñ∂ DownloadAll to grab all files.')\n",
    "    print('   Place asl_word_lstm_v2_best.h5 + scaler.pkl + encoder.pkl')\n",
    "    print('   + asl_word_classes_v2.csv into your live-test folder.')\n",
    "else:\n",
    "    print(f'\\nüìÇ Local path: {OUTPUT_DIR.resolve()}')\n",
    "\n",
    "print('\\n' + '=' * 65)\n",
    "print('‚úÖ  ALL DONE')\n",
    "print('=' * 65)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
